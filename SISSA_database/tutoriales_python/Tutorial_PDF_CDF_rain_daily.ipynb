{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78563f4f-66b9-4c29-b6ac-59e73f25561b",
   "metadata": {},
   "source": [
    "# Analizamos cómo el modelo representa aspectos de la distribución de una variable\n",
    "\n",
    "En este tutorial vamos a explorar como es la distribución de probabilidades en el modelo para un punto:\n",
    "- Vamos a seleccionar un punto\n",
    "- Tomar datos diarios correspondiende a la semana 2\n",
    "- Calcular la función de distribución de probabilidad y la función de distribución de probabilidad acumulada\n",
    "En este caso vamos a trabajar con la variable precipitación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01fbc4dd-08f9-4103-bdd7-8813806d12c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partimos importando los modulos a utilizar:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import s3fs\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e7f0a0-0c67-41d2-9a8f-f3a97e120dc2",
   "metadata": {},
   "source": [
    "Primero definimos algunas funciones que vamos a usar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecec99de-92b5-440f-9d35-4485b9531ea3",
   "metadata": {},
   "source": [
    "Vamos a estudiar la distribucion para un punto, con la variable lluvia para las fechas alrededor del día 5/2/2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d79a5c3-c084-4ebc-8ca6-bb7bf1f9bf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = 'rain'\n",
    "lat = -29.18\n",
    "lon = -58.07\n",
    "ref_date = datetime.datetime.strptime('20180502', \"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23659efe-cade-49b2-965d-fc2285195e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion para acomodar xarrays antes de concatenarlos\n",
    "def preprocess_ds(ds, variable=variable):\n",
    "    ds = ds.assign_coords(S=ds.time.values[0], M=int(ds[variable].encoding['source'][-6:-4]))\n",
    "    ds['time'] = ds.time.values - ds.time.values[0]\n",
    "    ds = ds.rename({'time': 'leadtime'})\n",
    "    return ds\n",
    "\n",
    "# funcion para calcular la CDF de los datos\n",
    "def calcular_cdf(datos):\n",
    "    n = len(datos)\n",
    "    x_ordenados = np.sort(datos)\n",
    "    cdf = np.arange(1, n + 1) / n\n",
    "    return x_ordenados, cdf\n",
    "\n",
    "# función para obtener el segundo dato de cada grupo\n",
    "def get_second_data(group):\n",
    "    return group.isel(S=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38efb674-c488-4bef-8a10-3cce92fed661",
   "metadata": {},
   "source": [
    "Vamos a tomar de la base de datos de sissa los datos corregidos. Vamos a ver como se programa para seleccionar todas las fechas alrededor del 2 de mayo de cada año del período 2010-2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792465a2-5cc0-43fd-a22d-ff939072f248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATOS CORREGIDOS\n",
    "fs = s3fs.S3FileSystem(anon=True)\n",
    "BUCKET_NAME = 'sissa-forecast-database'\n",
    "tforecast = 'subseasonal'\n",
    "modelo = 'GEFSv12_corr'\n",
    "list_df = []\n",
    "for i in np.arange(2010, 2020, 1): #loop sobre años\n",
    "    loop_date = ref_date.replace(year=i) - timedelta(days=15) # reemplazo el año y arranco 15 días antes de la fecha\n",
    "    while loop_date < (ref_date.replace(year=i) + timedelta(days=15)): # el loop es hasta 15 días despues\n",
    "        if loop_date.weekday() == 2: # los pronos están disponibles los miercoles\n",
    "            PATH = tforecast + '/' + modelo + '/' + variable + '/' + loop_date.strftime('%Y') + '/' + loop_date.strftime('%Y%m%d') + '/'            \n",
    "            # Listamos todos los archivos dentro del bucket + PATH\n",
    "            remote_files = fs.glob('s3://' + BUCKET_NAME + '/' + PATH + '*.nc')\n",
    "            # Iterate through remote_files to create a fileset\n",
    "            fileset = [fs.open(file) for file in remote_files]\n",
    "            # This works\n",
    "            data = xr.open_mfdataset(fileset, combine='nested', concat_dim='M', preprocess=preprocess_ds)\n",
    "            data = data.sel(lat=lat, lon=lon, method='nearest')\n",
    "            list_df.append(data)\n",
    "            \n",
    "        loop_date += timedelta(days=1)\n",
    "\n",
    "ds_corr = xr.concat(list_df, dim='S')\n",
    "print(ds_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcba7766-fc28-493a-b669-9d369b53d735",
   "metadata": {},
   "source": [
    "Repetimos para los datos sin corregir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8962890-123f-4e57-80d5-2f442c191446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATOS SIN CORREGIR\n",
    "fs = s3fs.S3FileSystem(anon=True)\n",
    "BUCKET_NAME = 'sissa-forecast-database'\n",
    "tforecast = 'subseasonal'\n",
    "modelo = 'GEFSv12'\n",
    "list_df = []\n",
    "for i in np.arange(2010, 2020, 1): #loop sobre años\n",
    "    loop_date = ref_date.replace(year=i) - timedelta(days=15) # reemplazo el año y arranco 15 días antes de la fecha\n",
    "    while loop_date < (ref_date.replace(year=i) + timedelta(days=15)): # el loop es hasta 15 días despues\n",
    "        if loop_date.weekday() == 2: # los pronos están disponibles los miercoles\n",
    "            PATH = tforecast + '/' + modelo + '/' + variable + '/' + loop_date.strftime('%Y') + '/' + loop_date.strftime('%Y%m%d') + '/'            \n",
    "            # Listamos todos los archivos dentro del bucket + PATH\n",
    "            remote_files = fs.glob('s3://' + BUCKET_NAME + '/' + PATH + '*.nc')\n",
    "            # Iterate through remote_files to create a fileset\n",
    "            fileset = [fs.open(file) for file in remote_files]\n",
    "            # This works\n",
    "            data = xr.open_mfdataset(fileset, combine='nested', concat_dim='M', preprocess=preprocess_ds)\n",
    "            data = data.sel(lat=lat, lon=lon, method='nearest')\n",
    "            list_df.append(data)\n",
    "            \n",
    "        loop_date += timedelta(days=1)\n",
    "\n",
    "ds_uncal = xr.concat(list_df, dim='S')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cd906b-57bf-4768-870f-15a2c20b2f65",
   "metadata": {},
   "source": [
    "Abrimos los datos observados y selecciono la segunda semana a patir de los miercoles alrededor de la fecha de interes para los años de estudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c23d4c8-8bba-47bd-8508-b6e70895cb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos los datos de ERA5\n",
    "fs = s3fs.S3FileSystem(anon=True)\n",
    "BUCKET_NAME = 'sissa-forecast-database'\n",
    "tforecast = 'ERA5'\n",
    "modelo = 'ERA5'\n",
    "list_df = []\n",
    "PATH = tforecast + '/' + variable \n",
    "remote_files = fs.glob('s3://' + BUCKET_NAME + '/' + PATH + '/' + '*.nc')\n",
    "# Iterate through remote_files to create a fileset\n",
    "fileset = [fs.open(file) for file in remote_files]\n",
    "data = xr.open_mfdataset(fileset, combine='nested', concat_dim='time')\n",
    "data = data.sel(latitude=lat, longitude=lon, method='nearest')\n",
    "\n",
    "for i in np.arange(2010, 2020, 1):\n",
    "    loop_date = ref_date.replace(year=i) - timedelta(days=15)\n",
    "    while loop_date < (ref_date.replace(year=i) + timedelta(days=15)):\n",
    "        if loop_date.weekday() == 2:\n",
    "            era = data.sel(time= slice(loop_date + timedelta(days=8), loop_date + timedelta(days=14)))\n",
    "            era['S'] = loop_date\n",
    "            era['time'] = era['time'] - era['S']\n",
    "            list_df.append(era)\n",
    "        \n",
    "        loop_date += timedelta(days=1)\n",
    "ds_era = xr.concat(list_df, dim='S')\n",
    "ds_era = ds_era.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405b01dd-f753-4a69-91b1-e3e9e3c756a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds_corr, ds_uncal, ds_era)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e664aacb-8bb8-4538-9c30-c05bb5d7ead7",
   "metadata": {},
   "source": [
    "Selecciono la semana 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f049a893-958d-499f-8e06-ec3a3f362e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecciono semana 2 (8-14 dias)\n",
    "ds_corr_w2 = ds_corr.sel(leadtime=slice(np.timedelta64(8, 'D'), np.timedelta64(14, 'D'))).compute()\n",
    "print(ds_corr_w2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8e0025-51a5-477b-92eb-53c337b4f3dc",
   "metadata": {},
   "source": [
    "Repito para los datos corregidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e0d1f7-f8cf-4a22-9b3c-fa43becba1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecciono semana 2 (8-14 dias)\n",
    "ds_uncal_w2 = ds_uncal.sel(leadtime=slice(np.timedelta64(8, 'D'), np.timedelta64(14, 'D'))).compute()\n",
    "print(ds_uncal_w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95401455-5d31-442b-b6f6-c3d7fa413d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuste de los datos a una distribución normal\n",
    "aux_uncal =ds_uncal_w2[variable].values.flat\n",
    "aux_corr =ds_corr_w2[variable].values.flat\n",
    "aux_era = ds_era[variable].values.flat[~np.isnan(ds_era[variable].values.flat)] \n",
    "\n",
    "bins = np.arange(0, 60, 5)\n",
    "\n",
    "plt.hist(aux_uncal, bins, density=True, histtype='step', color='r', alpha=0.5, label='GEFS No-corregida', linewidth=1.5)\n",
    "plt.hist(aux_corr, bins, density=True, histtype='step', color='b', alpha=0.5, label='GEFS Corregida', linewidth=1.5)\n",
    "plt.hist(aux_era, bins, density=True, histtype='step', color='k', alpha=0.5, label='ERA5', linewidth=1.5)\n",
    "\n",
    "\n",
    "plt.xlabel(variable)\n",
    "plt.ylabel('Densidad de probabilidad')\n",
    "plt.title('Ajuste de datos a una distribución normal')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8c99f7-fe8f-45f8-a721-e3db7e68ded1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_ordenados1, cdf1 = calcular_cdf(aux_corr)\n",
    "x_ordenados2, cdf2 = calcular_cdf(aux_uncal)\n",
    "x_ordenados3, cdf3 = calcular_cdf(aux_era)\n",
    "\n",
    "# Plotear la CDF\n",
    "plt.plot(x_ordenados1, cdf1, 'b', label='Corregidos')\n",
    "plt.plot(x_ordenados2, cdf2, 'r', label='Sin corregir')\n",
    "plt.plot(x_ordenados3, cdf3, 'k', label='ERA5')\n",
    "plt.xlabel(variable)\n",
    "plt.ylabel('Probabilidad acumulada')\n",
    "plt.title('Función de Distribución Acumulativa (CDF)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56064cb5-8e73-46c1-9164-3f5d5809e10b",
   "metadata": {},
   "source": [
    "Ahora miramos la evolución de la lluvia acumulada para el segundo miercoles de mayo del registro. Vamos a ver cómo seleccionar los pronosticos inicializados esa segunda semana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a94b260-2b4b-4e5e-b9dc-8a531becf5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seleccionamos el me de mayo\n",
    "ds_corr_w2 = ds_corr_w2.sum('leadtime', skipna=True).isel(S= ds_uncal_w2.S.dt.month==5)\n",
    "ds_uncal_w2 = ds_uncal_w2.sum('leadtime', skipna=True).isel(S= ds_uncal_w2.S.dt.month==5)\n",
    "ds_era = ds_era.sum('time', skipna=True).isel(S= ds_era.S.dt.month==5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37608e0-f3b9-4e2a-a2e3-dec183df1da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds_corr_w2, ds_uncal_w2, ds_era)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfaca81-096c-4a77-9960-fedce7499d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecciona el segundo miércoles de cada mes\n",
    "ds_corr_w2_smier = ds_corr_w2.groupby('S.year').apply(get_second_data)\n",
    "ds_uncal_w2_smier = ds_uncal_w2.groupby('S.year').apply(get_second_data)\n",
    "ds_era_w2_smier = ds_era.groupby('S.year').apply(get_second_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1701b575-87d0-4be5-ad99-e15788018a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ds_uncal_w2_smier[variable].plot.scatter(x='year',color='gray', alpha=0.5, label='sin corregir')\n",
    "ds_era_w2_smier[variable].plot.scatter(x='year', color='k', label='ERA 5')\n",
    "plt.axis([2009, 2020, 0, 200])\n",
    "plt.legend()\n",
    "plt.savefig(variable + '_sin_corregir.jpg', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fef055-a86b-4503-a539-d9beaee31683",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ds_corr_w2_smier[variable].plot.scatter(x='year', color='orange', alpha=0.5, label='corregido')\n",
    "ds_era_w2_smier[variable].plot.scatter(x='year', color='k', label='ERA 5')\n",
    "plt.axis([2009, 2020, 0, 200])\n",
    "plt.legend()\n",
    "plt.savefig(variable + '_corregido.jpg', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30450318-bfdf-4e70-9b0f-8497cac9e38d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
